{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57574bc68940a861",
   "metadata": {},
   "source": [
    "# 1. 图像分割和实例分割"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe3832229739ef0",
   "metadata": {},
   "source": [
    "# 2. Pascal VOC2012 语义分割数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba3084ea7db894b",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932a885922d78072",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from utils.read_utils import read_voc_images\n",
    "\n",
    "voc_dir = '../data/VOCdevkit/VOC2012'\n",
    "train_features, train_labels = read_voc_images(voc_dir, True)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n = 5\n",
    "imgs = train_features[0:n] + train_labels[0:n]\n",
    "\n",
    "# 图像一般存储为 (通道数, 高度, 宽度) 的格式，\n",
    "# 为了正确显示图像，需要将其转换为 (高度, 宽度, 通道数) 的格式\n",
    "imgs = [img.permute(1, 2, 0) for img in imgs]\n",
    "d2l.show_images(imgs, 2, n);"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4dadfbd18960d4d2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 列举RGB颜色值和类名\n",
    "\n",
    "VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n",
    "                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n",
    "                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n",
    "                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n",
    "                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n",
    "                [0, 64, 128]]\n",
    "\n",
    "VOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
    "               'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "               'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor']"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a2b8551fd23bc90e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RGB 颜色空间的每个通道有 256 个可能的取值（从 0 到 255）\n",
    "因此，RGB 颜色组合总数为：256×256×256=16777216\n",
    "\n",
    "R: 红色通道，取值范围为 0 到 255\n",
    "G: 绿色通道，取值范围为 0 到 255\n",
    "B: 蓝色通道，取值范围为 0 到 255\n",
    "\n",
    "(R * 256 + G) * 256 + B 不会超过 256 × 256 × 256\n",
    "\n",
    "为什么是这样的公式？\n",
    "\n",
    "首先B做贡献 0-255\n",
    "          =>目前可表示范围 0-255\n",
    "          \n",
    "接着G做贡献 1 * 256 + B(0-255) 、 2 * 256 + B(0-255)  ...    255 * 256 + B(0-255)\n",
    "          =>目前可表示范围 0- (255 * 256 + 255)\n",
    "                       =0- (256 * 256 -1)    \n",
    "            \n",
    "最后R做贡献 (1 * 256) * 256 + G(0-255) * 256 + B(0-255) ... (2 * 256) * 256 + G(0-255) * 256 + B(0-255)\n",
    "          =>目前可表示范围 0- (255 * 256) * 256 + 255 * 256 + 255 \n",
    "                       =0- (255 * 256 + 255) * 256 + 255\n",
    "                       =0- (256 *256 -1) * 256 + 255\n",
    "                       =0- (256 *256 *256) -256 +255\n",
    "                       =0- (256 *256 *256) -1\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "返回值： 每个VOC_COLORMAP中每个RGB对应的类别\n",
    "\n",
    "类别用数字表示\n",
    "范围=length(VOC_COLORMAP)\n",
    "\"\"\"\n",
    "def voc_colormap2label():\n",
    "    \"\"\"构建从RGB到VOC类别索引的映射\"\"\"\n",
    "    colormap2label = torch.zeros(256 ** 3, dtype=torch.long)\n",
    "    for i, colormap in enumerate(VOC_COLORMAP):\n",
    "        colormap2label[\n",
    "            (colormap[0] * 256 + colormap[1]) * 256 + colormap[2]] = i\n",
    "    return colormap2label\n",
    "\n",
    "\"\"\"\n",
    "【计算图像的类别值】\n",
    "每个图像的每个像素对应的分类索引，再计算出分类索引对应的类别值\n",
    "\"\"\"\n",
    "def voc_label_indices(colormap, colormap2label):\n",
    "    \"\"\"将VOC标签中的RGB值映射到它们的类别索引\"\"\"\n",
    "    colormap = colormap.permute(1, 2, 0).numpy().astype('int32')\n",
    "    idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256\n",
    "           + colormap[:, :, 2])\n",
    "    return colormap2label[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "cec13f246abd9275",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(train_labels[0].permute(1, 2, 0).shape[0:2])\n",
    "\n",
    "y = voc_label_indices(train_labels[0], voc_colormap2label())\n",
    "y[105:115, 130:140], VOC_CLASSES[1]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "42e24fdeec0daa88",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y[105:115, 330:340], VOC_CLASSES[1]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "af478c8aee0af62c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1. 预处理数据"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2b6776b630c130c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "【对输入的图像和标签进行随机裁剪】\n",
    "    feature: 输入的特征图像（通常为RGB图像或特征图）\n",
    "    label: 输入的标签图像（对应于分割任务中的标签）\n",
    "    height : 裁剪后的目标图像高度\n",
    "    width : 裁剪后的目标图像宽度\n",
    "\"\"\"\n",
    "def voc_rand_crop(feature, label, height, width):\n",
    "    \n",
    "    # 获取裁剪的随机参数：返回一个包含 (top, left, height, width) 的元组\n",
    "    rect = torchvision.transforms.RandomCrop.get_params(feature, (height, width))\n",
    "    # 使用裁剪参数裁剪特征图像\n",
    "    feature = torchvision.transforms.functional.crop(feature, *rect)\n",
    "    # 使用相同的裁剪参数裁剪标签图像\n",
    "    label = torchvision.transforms.functional.crop(label, *rect)\n",
    "    # 返回裁剪后的特征图像和标签图像\n",
    "    return feature, label\n",
    "\n",
    "imgs = []\n",
    "for _ in range(n):\n",
    "    imgs += voc_rand_crop(train_features[0], train_labels[0], 200, 300)\n",
    "\n",
    "imgs = [img.permute(1, 2, 0) for img in imgs]\n",
    "d2l.show_images(imgs[::2] + imgs[1::2], 2, n);"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b30a495e1beec0d4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2. 自定义语义分割数据集类"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2672214d2a8f417a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "【加载并预处理 VOC 数据集中的图像和标签】\n",
    "\"\"\"\n",
    "class VOCSegDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"一个用于加载VOC数据集的自定义数据集\"\"\"\n",
    "\n",
    "    def __init__(self, is_train, crop_size, voc_dir):\n",
    "        \n",
    "        # 图像像素值标准化\n",
    "        self.transform = torchvision.transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        # 裁剪尺寸，用于裁剪输入图像和标签图像\n",
    "        self.crop_size = crop_size\n",
    "        \n",
    "        # 加载图像和标签\n",
    "        features, labels = read_voc_images(voc_dir, is_train=is_train)\n",
    "        \n",
    "        # 过滤图像，并将像素值标准化\n",
    "        self.features = [self.normalize_image(feature) for feature in self.filter(features)]\n",
    "        \n",
    "        # 过滤标签\n",
    "        self.labels = self.filter(labels)\n",
    "        self.colormap2label = voc_colormap2label()\n",
    "        print('read ' + str(len(self.features)) + ' examples')\n",
    "\n",
    "    \"\"\"\n",
    "    【图像像素值标准化】\n",
    "    \"\"\"\n",
    "    def normalize_image(self, img):\n",
    "        return self.transform(img.float() / 255)\n",
    "\n",
    "    \"\"\"\n",
    "    【过滤掉尺寸小于裁剪大小的图像】\n",
    "    \"\"\"\n",
    "    def filter(self, imgs):\n",
    "        return [img for img in imgs if (\n",
    "            img.shape[1] >= self.crop_size[0] and\n",
    "            img.shape[2] >= self.crop_size[1])]\n",
    "\n",
    "    \"\"\"\n",
    "    【根据索引获取图像和图像类别值】\n",
    "    \"\"\"\n",
    "    def __getitem__(self, idx):\n",
    "        feature, label = voc_rand_crop(self.features[idx], self.labels[idx],\n",
    "                                       *self.crop_size)\n",
    "        return (feature, voc_label_indices(label, self.colormap2label))\n",
    "\n",
    "    \"\"\"\n",
    "    【总图像数】\n",
    "    \"\"\"\n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "711814c9de24ec63",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3. 读取数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6170265b63d8ddc3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 定义目标裁剪尺寸\n",
    "crop_size = (320, 480)\n",
    "\n",
    "# 加载并预处理 VOC 数据集中的图像和标签\n",
    "voc_train = VOCSegDataset(True, crop_size, voc_dir)\n",
    "voc_test = VOCSegDataset(False, crop_size, voc_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "993672ffc0daaf82",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 如果这个单元格运行卡住了，把num_workers这项参数去掉就可以了，不需要多线程读取。\n",
    "batch_size = 64\n",
    "train_iter = torch.utils.data.DataLoader(voc_train, batch_size, shuffle=True,\n",
    "                                    drop_last=True)\n",
    "for X, Y in train_iter:\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d8c0fd0a6fe6cc5e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.4. 整合所有组件"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19d2ac28a3a8f4b4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_data_voc(batch_size, crop_size):\n",
    "    \"\"\"加载VOC语义分割数据集\"\"\"\n",
    "    num_workers = d2l.get_dataloader_workers()\n",
    "    train_iter = torch.utils.data.DataLoader(\n",
    "        VOCSegDataset(True, crop_size, voc_dir), batch_size,\n",
    "        shuffle=True, drop_last=True, num_workers=num_workers)\n",
    "    test_iter = torch.utils.data.DataLoader(\n",
    "        VOCSegDataset(False, crop_size, voc_dir), batch_size,\n",
    "        drop_last=True, num_workers=num_workers)\n",
    "    return train_iter, test_iter"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2388d86838f06dc4",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
